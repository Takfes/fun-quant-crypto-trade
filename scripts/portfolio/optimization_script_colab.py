"""05_Efficient_Frontier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B5nZT42KXp0mFenaCH9lo1y2B15rW0At

### Prepare Environment
"""

import datetime
import itertools
import random

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import plotly.graph_objs as go
import seaborn as sns
import yfinance as yf
from scipy.optimize import minimize

"""### Configuration"""

START = "2021-01-01"
# END = '2025-07-30'
END = datetime.date.today().strftime("%Y-%m-%d")

CLEAN_OUTLIERS_LB = None
CLEAN_OUTLIERS_UB = None

ASSET_WEIGHT_LB = 0.0
ASSET_WEIGHT_UB = 0.5

NUM_PORTFOLIOS = 10_000
SEED = 1990

"""### Select Tickers"""

usm = ["AMZN", "MSFT", "GOOG", "CMG", "MU", "MELI", "META", "NVDA"]

# grm = ['AEGN.AT','ALPHA.AT','CAIROMEZ.AT','OTOEL.AT', 'VIO.AT']

grm = [
    "AEGN.AT",
    "ALPHA.AT",
    "OTOEL.AT",
    "VIO.AT",
    "ELHA.AT",
    "VIO.AT",
    "TPEIR.AT",
    #    'AEGN.AT','ALPHA.AT','CAIROMEZ.AT','OTOEL.AT', 'VIO.AT','GCMEZZ.AT'
    #    'PVMEZZ.AT','SUNMEZZ.AT', 'ELHA.AT','LAMDA.AT',,'DIMAND.AT','ELLAKTOR.AT','QUEST.AT',
    #    'TITC.AT','OPTIMA.AT', 'GEKTERNA.AT','OPAP.AT','BELA.AT','INLOT.AT','MYTIL.AT',
]

holds = [
    "ETH-EUR",
    "IS3N.DE",
    "VUAA.L",
    "QDVE.DE",
    "XRP-EUR",
    "AETF.AT",
    "VIO.AT",
    "TPEIR.AT",
    "ELHA.AT",
    "OTOEL.AT",
    "AEGN.AT",
    #'ALPHA.AT',
]

crypto = ["BTC-USD", "ETH-USD", "SOL-USD", "XRP-USD"]

# tickers = usm + grm + etf
tickers = holds

"""### Download Data"""

rawdata = yf.download(tickers, start=START, end=END)
data = rawdata["Close"].copy()
data.isnull().sum()

returns_raw = data.pct_change(fill_method=None).dropna()

min_date = min(returns_raw.index)
max_date = max(returns_raw.index)
num_bdays = pd.bdate_range(start=min_date, end=max_date).size

print(
    f"\n {returns_raw.shape[0]}/{num_bdays} ({returns_raw.shape[0] / num_bdays:.2f}) observations from {min_date} to {max_date}"
)
returns_raw.describe().T

"""### Clean Data (Outlier Returns)"""

# Cleanup logic
returns = returns_raw.copy()


# --- Validate helpers ---
def _is_prob(x):
    return isinstance(x, (int, float)) and (0 < x <= 1)


# --- Start with a copy ---
returns = returns_raw.copy()

# --- Decide lower / upper quantile series (or None) ---
lower_q = None
upper_q = None

if CLEAN_OUTLIERS_LB is not None and _is_prob(CLEAN_OUTLIERS_LB):
    lower_q = returns_raw.quantile(CLEAN_OUTLIERS_LB, numeric_only=True)

if CLEAN_OUTLIERS_UB is not None and _is_prob(CLEAN_OUTLIERS_UB):
    upper_q = returns_raw.quantile(CLEAN_OUTLIERS_UB, numeric_only=True)

# (Optional) sanity check: if both present, ensure lower <= upper per column
if lower_q is not None and upper_q is not None:
    # if any column’s lower > upper due to degenerate data, swap for that column
    swap_mask = lower_q > upper_q
    if swap_mask.any():
        tmp = lower_q.copy()
        lower_q[swap_mask], upper_q[swap_mask] = upper_q[swap_mask], tmp[swap_mask]

# --- Apply clipping (Series bounds align by column; inf for missing sides) ---
returns = returns_raw.clip(
    lower=lower_q if lower_q is not None else -np.inf, upper=upper_q if upper_q is not None else np.inf, axis=1
)

returns.describe().T

# Total Returns in the Period
returns.add(1).prod().add(-1)

"""### Visualize Risk vs Returns"""

summary = returns.describe().T[["mean", "std"]]
summary.columns = ["Return", "Risk"]
summary.Return = summary.Return * 252
summary.Risk = summary.Risk * np.sqrt(252)
summary = summary.reset_index().copy()
summary

# Base scatter plot
fig = px.scatter(
    summary,
    x="Risk",
    y="Return",
    hover_name="Ticker",
    hover_data={"Risk": ":.3f", "Return": ":.3f"},
    template="plotly_white",
)
fig.update_traces(marker=dict(size=15))

# --- Annotate all points directly on plot ---
for _, row in summary.iterrows():
    fig.add_annotation(
        x=row["Risk"],
        y=row["Return"],
        text=row["Ticker"],
        showarrow=False,
        font=dict(size=15, color="black"),
        yshift=12,  # small vertical offset so it doesn’t overlap marker
    )

# Titles / labels
fig.update_layout(title="Mean–Variance Analysis", xaxis_title="Risk (std)", yaxis_title="Mean Return")

fig.show()

"""### Visualize Returns"""

# Melt the DataFrame into long format for seaborn
returns_long = returns.melt(var_name="Asset", value_name="Return")

# Create 2x1 grid
fig, axes = plt.subplots(2, 1, figsize=(12, 10), sharex=False)

# --- Violin plot ---
sns.violinplot(data=returns_long, x="Asset", y="Return", inner="quartile", cut=0, ax=axes[0])
axes[0].set_title("Distribution of Returns per Asset (Violin Plot)")

# --- KDE plots (all distributions overlapped) ---
sns.kdeplot(data=returns, fill=True, common_norm=False, alpha=0.3, ax=axes[1])
axes[1].set_title("KDE of Returns per Asset")

plt.tight_layout()
plt.show()

"""### Portfolio Simulation"""


# Function to generate weights with 0 allocation to assets
def generate_forced_weights(N, min_k=1, max_k=None, per_k=None, seed=None):
    if max_k is None:
        max_k = N
    if seed is not None:
        random.seed(seed)

    forced = []
    for k in range(min_k, max_k + 1):
        combos = list(itertools.combinations(range(N), k))
        if per_k is not None and len(combos) > per_k:
            combos = random.sample(combos, per_k)
        for combo in combos:
            w = np.zeros(N, dtype=float)
            w[list(combo)] = 1.0 / k
            forced.append(w)
    return forced


# Function to calculate portfolio performance
def portfolio_performance(weights, mean_returns, cov_matrix):
    returns = np.dot(weights, mean_returns)
    std_dev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
    return std_dev, returns


# N assets in the dataset
N = returns.shape[1]

# Generate combinations with zero weights
forced_weights = generate_forced_weights(N, min_k=1, per_k=1000, max_k=N - 1, seed=SEED)  # 1-asset + all 2-asset 50/50s

# How many random portfolios to generate
remaining_nbr_of_portfolios_to_generate_at_random = NUM_PORTFOLIOS - len(forced_weights)

# Generate random portfolios
random_weights = []
for i in range(remaining_nbr_of_portfolios_to_generate_at_random):
    weights = np.random.random(N)
    weights /= np.sum(weights)
    random_weights.append(weights)

# Combine forced-zero-weights portfolios with random-weights portfolios
loadings = forced_weights + random_weights

print(f"{len(forced_weights)=}")
print(f"{len(random_weights)=}")
print(f"{len(loadings)=}")

# Calculate returns & cov_matrix once
mean_returns = returns.mean() * 252
cov_matrix = returns.cov() * 252

# Container for portfolio results
results = np.zeros((3, NUM_PORTFOLIOS))

# Simulate random portfolios
for i, wdistr in enumerate(loadings):
    std_dev, return_ = portfolio_performance(wdistr, mean_returns, cov_matrix)
    results[0, i] = std_dev
    results[1, i] = return_
    results[2, i] = return_ / std_dev

# # Calculate annualized mean returns and the covariance matrix
# mean_returns = returns.mean() * 252
# cov_matrix = returns.cov() * 252

# # Container for portfolio results
# results = np.zeros((3, NUM_PORTFOLIOS))  # Reduced number for computational ease
# loadings = []

# # Function to calculate portfolio performance
# def portfolio_performance(weights, mean_returns, cov_matrix):
#     returns = np.dot(weights, mean_returns)
#     std_dev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
#     return std_dev, returns

# # Simulate random portfolios
# for i in range(NUM_PORTFOLIOS):
#     weights = np.random.random(len(mean_returns))
#     weights /= np.sum(weights)
#     std_dev, return_ = portfolio_performance(weights, mean_returns, cov_matrix)
#     results[0, i] = std_dev
#     results[1, i] = return_
#     results[2, i] = return_ / std_dev
#     loadings.append(weights)

"""### Portfolio Optimization"""


# Function to calculate portfolio return
def portfolio_return(weights, returns):
    return np.sum(returns.mean() * weights) * 252


# Function to calculate portfolio volatility
def portfolio_volatility(weights, returns):
    return np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))


# Function to be minimized (Sharpe ratio negated for maximization)
def negative_sharpe_ratio(weights, returns, risk_free_rate=0.01):
    p_returns = portfolio_return(weights, returns)
    p_vol = portfolio_volatility(weights, returns)
    return -(p_returns - risk_free_rate) / p_vol


# Function to calculate portfolio variance
def portfolio_variance(weights, returns):
    return np.dot(weights.T, np.dot(returns.cov() * 252, weights))


# Function to calculate Sortino Ratio
def negative_sortino_ratio(weights, returns, target=0.01):
    portfolio_returns = np.dot(returns, weights)
    downside_returns = portfolio_returns[portfolio_returns < target]
    downside_risk = np.std(downside_returns)
    return -np.mean(portfolio_returns) / downside_risk if downside_risk > 0 else float("inf")


# Function to calculate CVAR
def portfolio_cvar(weights, returns, alpha=0.1):
    portfolio_returns = np.dot(returns, weights)
    sorted_returns = np.sort(portfolio_returns)
    index = int(alpha * len(sorted_returns))
    cvar = sorted_returns[:index].mean()
    return -cvar  # Return negative CVaR for minimization


# Number of stocks
n = len(returns.columns)

# Constraints
constraints = {
    "type": "eq",
    "fun": lambda x: np.sum(x) - 1,  # Weights must sum to 1
}

# Bounds for each stock's weight
lower_bound = ASSET_WEIGHT_LB
upper_bound = ASSET_WEIGHT_UB
bounds = tuple((lower_bound, upper_bound) for _ in range(n))

# Initial guess
initial_guess = np.array([1.0 / len(returns.columns)] * len(returns.columns))

# Select objective function
objective_functions = {
    # 'max_return': lambda x: -portfolio_return(x, returns),
    # 'min_variance': lambda x: portfolio_variance(x, returns),
    "max_sharpe": lambda x: negative_sharpe_ratio(x, returns),
    "max_sortino": lambda x: negative_sortino_ratio(x, returns, target=0.01),
    "min_cvar": lambda x: portfolio_cvar(x, returns),
}


def optimize_multi_criteria():
    results = {}
    for criterion in objective_functions:
        objective = criterion
        result = minimize(
            objective_functions[objective], initial_guess, method="SLSQP", bounds=bounds, constraints=constraints
        )
        if result.success:
            # loadings_opt = {k:f'{v:.2%}' for k,v in zip(data.columns,result.x)}
            loadings_opt = {k: v for k, v in zip(data.columns, result.x)}

            print(f">> Criterion: {objective}")
            print(f"Expected return: {portfolio_return(result.x, returns):.2f}")
            print(f"Expected volatility: {portfolio_volatility(result.x, returns):.2f}")
            print(f"Objective function {objective} value: {-result.fun:.2f}")
            print(f"Optimal Loadings: {loadings_opt}")
            print()

            results[objective] = {}
            results[objective]["Expected return"] = portfolio_return(result.x, returns)
            results[objective]["Expected volatility"] = portfolio_volatility(result.x, returns)
            results[objective]["Objective function value"] = result.fun
            results[objective]["Optimal Loadings"] = loadings_opt

        else:
            print("Optimization failed:", result.message)
            results[objective] = None
    return results


optres = optimize_multi_criteria()

# Compile results
crr = [
    {"Objective": k, "Returns": v.get("Expected return"), "Risk": v.get("Expected volatility")}
    for k, v in optres.items()
]
crrdf = pd.DataFrame(crr)
cwedf = (
    pd.DataFrame([v.get("Optimal Loadings") for k, v in optres.items()], index=list(optres.keys()))
    .T.rename_axis("tickers")
    .reset_index()
)

"""### Plot Efficient Frontier"""

# Plotting with Plotly
fig = go.Figure()

# Plot all portfolios
fig.add_trace(
    go.Scatter(
        x=results[0],
        y=results[1],
        mode="markers",
        marker=dict(size=5, color=results[2], colorscale="Viridis", showscale=True),
        name="random_portfolios",
    )
)

# Define a list of marker symbols for diversity
marker_symbols = ["circle", "square", "diamond", "cross", "x"]

# Define a list of colors for diversity
colors = ["red", "blue", "green", "purple", "orange"]

# Highlight the different objective functions
for index, item in enumerate(crr):
    fig.add_trace(
        go.Scatter(
            x=[item.get("Risk")],
            y=[item.get("Returns")],
            mode="markers+text",  # Include text mode for annotations
            text=[item.get("Objective")],  # Label points with the name of the objective
            textposition="top center",
            marker=dict(
                color=colors[index % len(colors)],  # Use different colors
                size=10,
                symbol=marker_symbols[index % len(marker_symbols)],  # Use different symbols
            ),
            name=item.get("Objective"),
        )
    )


fig.update_layout(
    title="Efficient Frontier with Objectives Highlighted",
    xaxis_title="Volatility (Standard Deviation)",
    yaxis_title="Expected Return",
    legend_title="Legend",
    hovermode="closest",
    legend=dict(x=1.05, y=1),  # Adjust legend position to avoid overlap
)

# Show plot
fig.show()

"""### Optimal Loadings"""

cwedf_ = cwedf.set_index("tickers").copy()
cwedf_["mean_obj"] = cwedf_.mean(axis=1)
# cwedf_.sort_values(by='mean_obj',ascending=False).style.format("{:.2%}")
cwedf_.style.format("{:.2%}")

"""## Correlation Matrix (Returns)"""

correletion_matrix = returns.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correletion_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

correletion_matrix
